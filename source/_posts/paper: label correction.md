---
title: 'paper: label correction.md'
date: 2021-07-08 19:53:16
tags: Paper, Label Noise
img: /images/blackboard.jpg
mathjax: true
---

## Meta Label Correction for Noisy Label Learning

### 重点：

1. 需要clean data
2. 用LCN （label correction network）作为meta network生成corrected soft label
3. clothing也用了clean data，达到了75.78

### 主要解决的问题：
如何同时优化LCN和main network（用来做prediction）。

### 解决办法：bi-level optimization。
用语言来说，就是用LCN生成corrected soft label 之后，将生成的label用于训练main network, 训练出的来 main network要在clean data上有尽可能小的loss。

![图 1](https://i.loli.net/2021/07/08/fzAkTUE5u4BhldO.png)  


![图 2](https://i.loli.net/2021/07/08/AlPaU9ESIRJM524.png)  

### 启发
具体的我就不细看了，收获是：知道了可以用meta learning来做label correction。优化两个network的方法这里也有提供了。感觉可以用到gnn上。

比如，在graph上用meta-learning来学correct label，感觉这时候correct会比较简单，因为可以利用邻居的label。

本论文的一个假设：if the labels generated by the LCN are of high quality, then a classifier trained with such corrected  labels as supervision should achieve low loss on a separate set of clean examples.

也就是说，label correction一定要有一个能够衡量corrected label的质量的东西，这个论文使用的方法是，在clean data上做validation。

**问题**：未必会有clean data给你用。

## Robust Curriculum Learning: from clean label detection to noisy label self-correction 

### 解决的问题

Existing methods address this problem by (1) filtering out the noisy data and only using the clean data for training or (2) relabeling the noisy data by the model during training or by another model trained only on a clean dataset. However, the former does not leverage the features’ information of wrongly-labeled data, while the latter may produce wrong pseudo-labels for some data and introduce extra noises

无论是去掉noisy data还是用另一个网络来生成pesudo label都不靠谱。

### 解决思路

In particular, we start with learning from clean data and then gradually move to learn noisy-labeled data with pseudo labels produced by a time-ensemble of the model and data augmentations. Instead of using the instantaneous loss computed at the current step, our data selection is based on the dynamics of both the loss and output consistency for each sample across historical steps and different data augmentations, resulting in more precise detection of both clean labels and correct pseudo labels. 

先学clean data，然后在学pesudo label，这个label是用"time-ensemble of the model"以及数据增强来生成的。

另外，也不使用当前step的即时loss。相反选择数据的方式是看loss和output，看看它们在时间上和不同的数据增光上是否有一致性。这步没看懂。

### 重点
1. 认为即时loss并不稳定，它会受DNN randomnees的影响，如此删选出来的data会有累计误差，coteaching就解决的这个问题。这个是用来做data selection，用于currciculum learning的。

2. 不需要clean dataset

3. 如果某个corrected label上多个step上训练出来的output都比较一致，那么corrected label可能是对的。如果不同aug产生的output也一致，那么也可能是对的。  By analyzing the training dynamics of model outputs in the above experiment, we discover that the model output for a sample tends to be an accurate pseudo label if the output remains consistent over training steps and across different augmentations of the sample.

### 读后感

1. 本文其实也提出了一个用于判断corrected label quality的方法，即看它在多个step上学到的output是否一致、多种data augmentation之后学到的output是否一致。但是GNN上没那么多aug的方法，而且这种方法很耗时。


## Joint Optimization Framework for Learning with Noisy Labels
一个model，交替迭代，一步根据当前标签和model prediction求loss，并且更新model。另一部把model prediction作为soft标签。

重点，这里的loss不是简单的ce loss，而是三部分组成：

1. prediction 与 soft label之前的KL散度
2. prediction 与 class distribution之间的KL散度，没错这里要假设class的分布情况已经知道。并且作者表面对于imbalance dataset 和类别很多的dataset，效果不太好。但是clothing上效果还行。
3. prediction 的信息熵，这一步是为了让prediction更加的confident，尽量predict到一个类上。

被喷的点：超参依赖重。

我觉得：label correction的关键就是要如何让correct的尽可能对，但是这里感觉并无保证，loss2保证prediction尽可能符合原始分布，但是具体prediction结果依然可以是错的。loss3同理。loss1仅仅是让model去学soft label，也就是说，Joint给correction方向并不是很靠谱，即我们可以找到case完全满足上述约束，但是corrected label 100%错误。同时让上述loss为0.

## Probabilistic End-to-end Noise Correction for Learning with Noisy Labels
![图 1](https://i.loli.net/2021/07/23/jF7mONDzR3hAYnC.png)  

这个会稍好，因为有noisy label compatibility的约束，但是依然可以找到case，corrected label is same as noisy lable.

